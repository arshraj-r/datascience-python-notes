# Data Science, Machine Learning & Generative AI Notes

Welcome to my personal knowledge hub for mastering **Data Science**, **Machine Learning (ML)**, **Deep Learning (DL)**, **Natural Language Processing (NLP)**, and **Generative AI** using Python.

This repository serves as a collection of concise notes, cheat sheets, and hands-on code notebooks covering the most widely used packages in the field.

---

## 🚀 Goals of This Repository

- 📘 Build structured notes to revise before interviews or projects
- 🔍 Deepen understanding of key libraries via annotated examples
- ⚡ Serve as a quick-reference guide and mini-cheatsheet
- 🧩 Easily extendable to cover more packages or advanced topics

---

## Core Libraries Covered

### 🔹 General Data Science
- **NumPy**: Arrays, broadcasting, linear algebra
- **Pandas**: DataFrames, preprocessing, analysis
- **Matplotlib / Seaborn / Plotly**: Visualization

### 🔹 Machine Learning
- **scikit-learn (`sklearn`)**: Models, preprocessing, pipelines, metrics
- **XGBoost / LightGBM / CatBoost**: Gradient boosting algorithms

### 🔹 Deep Learning
- **PyTorch**: Tensors, autograd, training loops, nn modules
- **TensorFlow / Keras** *(optional)*

### 🔹 Natural Language Processing (NLP)
- **spaCy**: Pipelines, NER, POS tagging, custom models
- **NLTK**: Tokenization, parsing, classic NLP tasks
- **TextBlob / Gensim**: Text processing, topic modeling
- **Hugging Face (`transformers`, `datasets`, `tokenizers`)**: Pretrained models & pipelines

### 🔹 Generative AI / LLMs
- **transformers**: Pretrained LLMs like BERT, GPT, T5
- **datasets**: Load and preprocess datasets for LLM training
- **tokenizers**: Custom tokenization and fast tokenizers
- **peft**: Parameter-efficient fine-tuning (LoRA, adapters)
- **accelerate**: Fast and distributed training
- **bitsandbytes**: 4-bit/8-bit model quantization
- **gradio / streamlit**: Build ML model demos
- **langchain / llamaindex** *(optional)*: RAG systems, chaining LLM tools
- **openai / anthropic SDKs** *(optional)*: API access to hosted LLMs

---

## 📁 Repository Structure

```plaintext
datascience-python-notes/
│
├── README.md
│
├── numpy/
│   ├── README.md
│   └── examples.ipynb
│
├── pandas/
│   ├── README.md
│   └── examples.ipynb
│
├── matplotlib/
│   ├── README.md
│   └── examples.ipynb
│
├── seaborn/
│   ├── README.md
│   └── examples.ipynb
│
├── sklearn/
│   ├── README.md
│   └── examples.ipynb
│
├── xgboost/
│   ├── README.md
│   └── examples.ipynb
│
├── pytorch/
│   ├── README.md
│   └── examples.ipynb
│
├── spacy/
│   ├── README.md
│   └── examples.ipynb
│
├── nltk/
│   ├── README.md
│   └── examples.ipynb
│
├── huggingface/
│   ├── transformers/
│   │   ├── README.md
│   │   └── examples.ipynb
│   ├── datasets/
│   │   ├── README.md
│   │   └── examples.ipynb
│   ├── tokenizers/
│   │   ├── README.md
│   │   └── examples.ipynb
│   ├── peft/
│   │   ├── README.md
│   │   └── examples.ipynb
│   ├── accelerate/
│   │   ├── README.md
│   │   └── examples.ipynb
│   └── bitsandbytes/
│       ├── README.md
│       └── examples.ipynb
│
├── gradio/
│   ├── README.md
│   └── examples.ipynb
│
├── langchain/ *(optional)*
│   ├── README.md
│   └── examples.ipynb
│
├── utils/
│   └── helper_functions.py
```
---

## How to Use This Repo

- Explore any folder to dive into that package.
- Each `README.md` contains:
  - Cheat-sheet style summaries
  - Essential methods/classes
  - Quick tips
- Each `examples.ipynb` shows:
  - Hands-on code
  - Minimal working examples
  - Use cases and explanations

---


## 🤝 Contributing

If you'd like to contribute:
1. Fork the repo
2. Add notes or improve examples
3. Open a PR with your changes

---

## 💬 Feedback

If you have suggestions or want to collaborate on tutorials, feel free to reach out via GitHub issues.

---

## ⭐ If this helped you, consider giving it a star!
