# Data Science, Machine Learning & Generative AI Notes

Welcome to my personal knowledge hub for mastering **Data Science**, **Machine Learning (ML)**, **Deep Learning (DL)**, **Natural Language Processing (NLP)**, and **Generative AI** using Python.

This repository serves as a collection of concise notes, cheat sheets, and hands-on code notebooks covering the most widely used packages in the field.

---

## ğŸš€ Goals of This Repository

- ğŸ“˜ Build structured notes to revise before interviews or projects
- ğŸ” Deepen understanding of key libraries via annotated examples
- âš¡ Serve as a quick-reference guide and mini-cheatsheet
- ğŸ§© Easily extendable to cover more packages or advanced topics

---

## Core Libraries Covered

### ğŸ”¹ General Data Science
- **NumPy**: Arrays, broadcasting, linear algebra
- **Pandas**: DataFrames, preprocessing, analysis
- **Matplotlib / Seaborn / Plotly**: Visualization

### ğŸ”¹ Machine Learning
- **scikit-learn (`sklearn`)**: Models, preprocessing, pipelines, metrics
- **XGBoost / LightGBM / CatBoost**: Gradient boosting algorithms

### ğŸ”¹ Deep Learning
- **PyTorch**: Tensors, autograd, training loops, nn modules
- **TensorFlow / Keras** *(optional)*

### ğŸ”¹ Natural Language Processing (NLP)
- **spaCy**: Pipelines, NER, POS tagging, custom models
- **NLTK**: Tokenization, parsing, classic NLP tasks
- **TextBlob / Gensim**: Text processing, topic modeling
- **Hugging Face (`transformers`, `datasets`, `tokenizers`)**: Pretrained models & pipelines

### ğŸ”¹ Generative AI / LLMs
- **transformers**: Pretrained LLMs like BERT, GPT, T5
- **datasets**: Load and preprocess datasets for LLM training
- **tokenizers**: Custom tokenization and fast tokenizers
- **peft**: Parameter-efficient fine-tuning (LoRA, adapters)
- **accelerate**: Fast and distributed training
- **bitsandbytes**: 4-bit/8-bit model quantization
- **gradio / streamlit**: Build ML model demos
- **langchain / llamaindex** *(optional)*: RAG systems, chaining LLM tools
- **openai / anthropic SDKs** *(optional)*: API access to hosted LLMs

---

## ğŸ“ Repository Structure

```plaintext
datascience-python-notes/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ numpy/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ pandas/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ matplotlib/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ seaborn/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ sklearn/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ xgboost/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ pytorch/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ spacy/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ nltk/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ huggingface/
â”‚   â”œâ”€â”€ transformers/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ examples.ipynb
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ examples.ipynb
â”‚   â”œâ”€â”€ tokenizers/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ examples.ipynb
â”‚   â”œâ”€â”€ peft/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ examples.ipynb
â”‚   â”œâ”€â”€ accelerate/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ examples.ipynb
â”‚   â””â”€â”€ bitsandbytes/
â”‚       â”œâ”€â”€ README.md
â”‚       â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ gradio/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ langchain/ *(optional)*
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ examples.ipynb
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ helper_functions.py
```
---

## How to Use This Repo

- Explore any folder to dive into that package.
- Each `README.md` contains:
  - Cheat-sheet style summaries
  - Essential methods/classes
  - Quick tips
- Each `examples.ipynb` shows:
  - Hands-on code
  - Minimal working examples
  - Use cases and explanations

---


## ğŸ¤ Contributing

If you'd like to contribute:
1. Fork the repo
2. Add notes or improve examples
3. Open a PR with your changes

---

## ğŸ’¬ Feedback

If you have suggestions or want to collaborate on tutorials, feel free to reach out via GitHub issues.

---

## â­ If this helped you, consider giving it a star!
